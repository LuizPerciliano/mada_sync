# Projeto final üéâ do Curso de FastAPI do ZERO com o ü¶ñ Dunossauro

__status em andamento__

FastAPI √© um framework Python moderno, projetado para simplicidade, velocidade e efici√™ncia, facilitando o desenvolvimento de APIs.

## 01 Entendimento do Neg√≥cio
O objetivo do projeto √© criarmos uma gerenciador de livros e relacionar com seus autores. Tudo isso em um contexto bastante simplificado. 

A implementa√ß√£o ser√° baseada em 3 pilares:
![alt text](image.png)

A API dividiremos os endpoints em tr√™s routers:
1. contas: Gerenciamento de contas e de acesso √† API
2. livros: Gerenciamento de livros
3. romancistas: Gerenciamento de romancistas

Demais detalhes em: https://fastapidozero.dunossauro.com/14/#o-projeto


## 02 Configurando o Ambiente de Desenvolvimento
1. definindo a ferramenta ou IDE de desenvolvimento <br>
    1. VSCode + Terminal (Windows)
1. no terminal verificar a instala√ß√£o e vers√£o do Python
1. Se necess√°rio, instala√ß√£o do pyenv, recomendado usar o pyenv-windows
    1. verificar qual vers√£o do python deseja e instalar
    2. atualizar o pyenv
    3. instalar uma vers√£o do python com o pyenv
    4. definir a vers√£o globao do python
1. Instala√ß√£o de ferramentas / bibliotecas recomendadas<br>
    1. pipx (O pipx √© uma ferramenta para instalar e gerenciar aplicativos Python isoladamente, ou seja, ela permite que voc√™ instale pacotes Python que s√£o aplicativos de linha de comando em ambientes virtuais pr√≥prios, sem interferir no ambiente global de pacotes do Python instalado no seu sistema.) 
    2. poetry
1. poetry <br>
    1. ap√≥s instalado, executar o comando "pipx ensurepath", fechar e reabrir o terminal
    2. entrar no diret√≥rio onde se deseja criar o projeto e cri√°-lo com o poetry
    3. definir qual a vers√£o do Python ser√° utilizada nesse projeto/diret√≥rio "pyenv local 3.12.5"
    4. criar o ambiente virtual (venv), que criar√° um arquivo oculto chamado `.python-version` na raiz do projeto, este deve ser alterado para 
    [tool.poetry.dependencies]
    python = "3.12.*"

    o * quer dizer qualquer vers√£o da 3.12

    5. inicializar o ambiente virtual
1. escrevendo no `README.MD` (atualizando sempre)
1. instalando a biblioteca do FastAPI

### Execu√ß√£o dos comandos em ordem conforme necessidade
~~~shell
python --version
pyenv --version
pyenv update
pyenv versions # verifica as vers√µes no sistema e qual est√° setado como principal
pyenv install --list # verifica a lista das vers√µes Python dispon√≠vel e pode pegar a √∫tlima "lberada"
pyenv install 3.12.5
pyenv versions
pyenv global 3.12.5
pyenv versions

pip install pipx
pipx install poetry
pipx install ignr
pipx ensurepath # executar ap√≥s poetry instalado, fechar e reabrir o terminal

cd C:\projetos\projetos-GIT\

# Criando o projeto
poetry new mada
cd mada
pyenv local 3.12.5 # dizer ao pyenv qual vers√£o do python ser√° usada nesse diret√≥rio
poetry install # Cria o ambiente virtual (venv)
~~~

### Primeira Execu√ß√£o de um "Hello, World!" teste no terminal

~~~shell
poetry shell
poetry add fastapi # Adiciona o FastAPI no nosso ambiente virtual
poetry add fastapi[standard] # deu erro s√≥ com o comando acima e pediu esse

# Criando a aplica√ß√£o e testando
echo > mada/app.py
~~~

Arquivo inicial `app.py`

~~~python
from fastapi import FastAPI

app = FastAPI()


@app.get('/')
def read_root():
    return {'message': 'Ol√° Mundo!'}
~~~

Executar a fun√ß√£o pelo terminal em modo interativo para chamar a fun√ß√£o.
~~~shell
python -i .\mada\app.py
>>> read_root()
~~~

### Testando o ambiente web: iniciar nosso servidor FastAPI para iniciar nossa aplica√ß√£o
~~~shell
fastapi dev mada/app.py
~~~

Com os testes no terminal e na web ok, pr√≥ximo passo:

#### Instalando + ferramentas de desenvolvimento
~~~shell
poetry add --group dev pytest pytest-cov taskipy ruff httpx
~~~

Ap√≥s a instala√ß√£o das ferramentas de desenvolvimento, precisamos definir as configura√ß√µes de cada uma individualmente no arquivo `pyproject.toml`.

~~~toml
[tool.ruff]
line-length = 79
extend-exclude = ['migrations']
~~~

~~~toml
[tool.ruff.lint]
preview = true
select = ['I', 'F', 'E', 'W', 'PL', 'PT']
~~~

~~~toml
[tool.ruff.format]
preview = true
quote-style = 'single'
~~~

~~~toml
[tool.pytest.ini_options]
pythonpath = "."
addopts = '-p no:warnings'
~~~

~~~toml
[tool.taskipy.tasks]
lint = 'ruff check . && ruff check . --diff'
format = 'ruff check . --fix && ruff format .'
run = 'fastapi dev mada/app.py'
pre_test = 'task lint'
test = 'pytest -s -x --cov=mada -vv'
post_test = 'coverage html'
~~~

__OBS.:__ atentar para os nomes dos projetos que influencia neste arqvuivo.

Ap√≥s arquivo configurado, pode testar os comandos criados para o taskipy:
~~~shell
task lint
task format
task lint
~~~

## Introdu√ß√£o ao Pytest: Testando o "Hello, World!"
~~~shell
task test
~~~

As linhas no terminal s√£o referentes ao pytest, que disse que coletou 0 itens. Nenhum teste foi executado.

Por n√£o encontrar nenhum teste, o pytest retornou um "erro". Isso significa que nossa tarefa post_test n√£o foi executada. Podemos execut√°-la manualmente:

~~~shell
task post_test
~~~

O comando acima gera um relat√≥rio de cobertura de testes em formato HTML no diret√≥rio `htmlcov.html`. Pode abrir esse arquivo no navegador e entender exatamente quais linhas do c√≥digo n√£o est√£o sendo testadas em `htmlcov\index.html`.
~~~shell
coverage html # Wrote HTML report to htmlcov\index.html
~~~

### Escrevendo o teste
Cria√ß√£o dos arquivos de teste.
~~~shell
echo > tests/test_app.py
~~~

Conte√∫do do arquivo:
~~~python
from fastapi.testclient import TestClient  

from mada.app import app  

client = TestClient(app)
~~~

~~~shell
task format
task test 
~~~

Por n√£o coletar nenhum teste, o pytest ainda retornou um "erro". Para ver a cobertura, precisaremos executar novamente o post_test manualmente:
~~~shell
task post_test
~~~

Para resolver isso, temos que criar um teste de fato, fazendo uma chamada para nossa API usando o cliente de teste que definimos e testar novamente.

![alt text](image.png)

Com base nesse c√≥digo, podemos observar as tr√™s fases:

__Fase 1 - Organizar (Arrange)__
Nesta primeira etapa, estamos preparando o ambiente para o teste. No exemplo, a linha com o coment√°rio Arrange n√£o √© o teste em si, ela monta o ambiente para que o teste possa ser executado. Estamos configurando um client de testes para fazer a requisi√ß√£o ao app.

__Fase 2 - Agir (Act)__
Aqui √© a etapa onde acontece a a√ß√£o principal do teste, que consiste em chamar o Sistema Sob Teste (SUT). No nosso caso, o SUT √© a rota /, e a a√ß√£o √© representada pela linha response = client.get('/'). Estamos exercitando a rota e armazenando sua resposta na vari√°vel response. √â a fase em que o c√≥digo de testes executa o c√≥digo de produ√ß√£o que est√° sendo testado. Agir aqui significa interagir diretamente com a parte do sistema que queremos avaliar, para ver como ela se comporta.

__Fase 3 - Afirmar (Assert)__
Esta √© a etapa de verificar se tudo correu como esperado. √â f√°cil notar onde estamos fazendo a verifica√ß√£o, pois essa linha sempre tem a palavra reservada assert. A verifica√ß√£o √© booleana, ou est√° correta, ou n√£o est√°. Por isso, um teste deve sempre incluir um assert para verificar se o comportamento esperado est√° correto.

### Criando o reposit√≥rio no git

[... deu muito ruim nessa parte do git, refazer outro projeto com cuidado. no pr√≥ximo, testar sem definir "-b main"]

Criar um arquivo `.gitignore` para n√£o adicionar o ambiente virtual e outros arquivos desnecess√°rios no versionamento de c√≥digo.
~~~shell
ignr -p python > .gitignore
~~~

Criar um novo reposit√≥rio no Git local para versionar o c√≥digo e definir a branch main como padr√£o. Caso n√£o coloque a branch como main, est√° criando como master.
~~~shell
git init -b main
~~~


Para criar um reposit√≥rio remoto no GitHub externo caso n√£o exista, usar o comando abaixo:
~~~shell
gh repo create
~~~

#### Respostas do gh
~~~shell
- Create a new repository on GitHub from scratch # ok (Enter)
- mada_sync
- Projeto Final do curso do Dunossauro (FASTAPI)
- Public
- N
- N
- y
- GNU General Public License v3.0
- Y
- Y
~~~

Imagem abaixo com resultado da cria√ß√£o do reposit√≥rio
![alt text](image-1.png)

__Atualizando o reposit√≥rio - Commit__ <br>
Se for um novo reposit√≥rio, deve-se adicionar o endere√ßo de origem no local com o comando abaixo:

~~~shell
git remote add origin https://github.com/LuizPerciliano/mada_sync
~~~

Caso seja um reposit√≥rio de desenvolvimento compartilhado, verificar se no reposit√≥rio remoto h√° algo novo e pedir para baixar.
~~~shell
git pull
~~~

Verificar o status do reposit√≥rio para ver as mudan√ßas realizadas:
~~~shell
git status
~~~

Se tudo estiver ok, adicionar os arquivos, comitar e por fim enviar para o reposit√≥rio remoto.
~~~shell
git add . 
git commit -m "Criado o projeto final do curso de FastAPI do Dunossauro"
git push --set-upstream origin main 
~~~

~~~shell
git push --force origin main # deu problema para subir, com isso foi
~~~

Conferindo se subiu tudo ok
~~~shell
git log
~~~

__Instala√ß√µes se necess√°rio__
~~~shell
Invoke-WebRequest -UseBasicParsing -Uri "https://raw.githubusercontent.com/pyenv-win/pyenv-win/master/pyenv-win/install-pyenv-win.ps1" -OutFile "./install-pyenv-win.ps1"; &"./install-pyenv-win.ps1"
~~~


## 03 Desenvolvendo a aplica√ß√£o ‚ö† :bowtie:

### Pydantic 
No universo de APIs e contratos de dados, especialmente ao trabalhar com Python, o Pydantic se destaca como uma ferramenta poderosa e vers√°til. Essa biblioteca, altamente integrada ao ecossistema Python, especializa-se na cria√ß√£o de schemas de dados e na valida√ß√£o de tipos. Com o Pydantic, √© poss√≠vel expressar schemas JSON de maneira elegante e eficiente atrav√©s de classes Python, proporcionando uma ponte robusta entre a flexibilidade do JSON e a seguran√ßa de tipos de Python.

Por exemplo, o schema JSON {'message': 'Ol√° mundo!'}. Com o Pydantic, podemos representar esse schema na forma de uma classe Python chamada Message.

Para iniciar o desenvolvimento com schemas no contexto do FastAPI, podemos criar um arquivo chamado mada/schemas.py e definir a classe Message. Vale ressaltar que o Pydantic √© uma depend√™ncia integrada do FastAPI (n√£o precisa ser instalado), refletindo a import√¢ncia dessa biblioteca no processo de valida√ß√£o de dados e na gera√ß√£o de documenta√ß√£o autom√°tica para APIs, como a documenta√ß√£o OpenAPI.

~~~shell
echo > mada/schemas.py
~~~

### Criando Rotas CRUD
1. criar o diret√≥rio de rotas
1. criar as rotas necess√°rias
1. criar o esquema do pydantic
1. criar o modelo
1. criar a base de dados
1. criar a seguran√ßa 
1. definir as configura√ß√µes

~~~shell
mkdir mada/routers
~~~

~~~shell
echo > mada/routers/usuario.py
echo > mada/routers/livro.py
echo > mada/routers/autor.py
~~~

## Criando um banco de dados falso

### Modelo de dados
Arquivo `mada/schemas.py`.
~~~python
class UserSchema(BaseModel):
    username: str
    email: str
    password: str
~~~

## Valida√ß√£o e pydantic

Valida√ß√£o de email
Instalando + ferramentas de desenvolvimento 
~~~shell
poetry add "pydantic[email]"
~~~

# Configurando o Banco de Dados e Gerenciando Migra√ß√µes com Alembic

Instalando + ferramentas de desenvolvimento 
~~~shell
poetry add sqlalchemy
~~~

~~~shell
poetry add pydantic-settings
~~~

Agora definiremos nosso modelo User. No diret√≥rio mada, crie um novo arquivo chamado models.py.

## Testando as Tabelas
Criaremos uma fixture para a conex√£o com o banco de dados chamada session no arquivo `tests/conftest.py`.

### Criando um Teste para a Nossa Tabela
Agora, no arquivo test_db.py, escreveremos um teste para a cria√ß√£o de um usu√°rio. Este teste adiciona um novo usu√°rio ao banco de dados, faz commit das mudan√ßas, e depois verifica se o usu√°rio foi devidamente criado consultando-o pelo nome de usu√°rio. Se o usu√°rio foi criado corretamente, o teste passa. Caso contr√°rio, o teste falha, indicando que h√° algo errado com nossa fun√ß√£o de cria√ß√£o de usu√°rio.

~~~shell
echo > tests/test_db.py
~~~

#### Executando o teste

## Configura√ß√£o do ambiente do banco de dados
~~~shell
echo > mada/settings.py
~~~

Agora, definiremos o DATABASE_URL no nosso arquivo de ambiente `.env`. Crie o arquivo na raiz do projeto e adicione a seguinte linha:
~~~shell
echo > .env
~~~

~~~shell
echo 'database.db' >> .gitignore
~~~

## Instalando o Alembic e Criando a Primeira Migra√ß√£o
~~~shell
poetry add alembic
~~~

Ap√≥s a instala√ß√£o do Alembic, precisamos inici√°-lo em nosso projeto. O comando de inicializa√ß√£o criar√° um diret√≥rio migrations e um arquivo de configura√ß√£o alembic.ini:
~~~shell
alembic init migrations
~~~

### Criando uma migra√ß√£o autom√°tica
Com o Alembic devidamente instalado e iniciado, agora √© o momento de gerar nossa primeira migra√ß√£o. Mas, antes disso, precisamos garantir que o Alembic consiga acessar nossas configura√ß√µes e modelos corretamente. Para isso, faremos algumas altera√ß√µes no arquivo migrations/env.py.

Para criar a migra√ß√£o, utilizamos o seguinte comando:
~~~shell
alembic revision --autogenerate -m "create users table"
~~~

### Analisando a migra√ß√£o autom√°tica
Vamos abrir e analisar o arquivo de migra√ß√£o `migrations/versions/f3577cecc9f1_create_users_table.py`.

Vamos acessar o console do sqlite e verificar se isso foi feito. Precisamos chamar sqlite3 nome_do_arquivo.db ou usar uma aplicativo que abre diversos tipos de banco de dados como o DBeaver:
~~~shell
sqlite3 database.db
~~~

Para aplicar as migra√ß√µes, usamos o comando upgrade do CLI Alembic. O argumento head indica que queremos aplicar todas as migra√ß√µes que ainda n√£o foram aplicadas:
~~~shell
alembic upgrade head
~~~

# Integrando Banco de Dados a API
Para isso, criaremos a fun√ß√£o get_session e tamb√©m definiremos Session no arquivo `database.py`.
~~~shell
echo > .\mada\database.py
~~~

## Modificando o Endpoint POST /users

### Testando o Endpoint POST /users com Pytest e Fixtures
Alteraremos a nossa fixture client para substituir a fun√ß√£o get_session que estamos injetando no endpoint pela sess√£o do banco em mem√≥ria que j√° t√≠nhamos definido para banco de dados.

### Integrando o Schema ao Model
ajustando o arquivo `mada/schemas.py` <p>

# Autentica√ß√£o e Autoriza√ß√£o com JWT
## Gerando tokens JWT
Para gerar tokens JWT, precisamos de duas bibliotecas extras: pyjwt e pwdlib. A primeira ser√° usada para a gera√ß√£o do token, enquanto a segunda ser√° usada para criptografar as senhas dos usu√°rios. Para instal√°-las, execute o seguinte comando no terminal:
~~~shell
poetry add pyjwt "pwdlib[argon2]"
~~~

Agora, criaremos uma fun√ß√£o para gerar nossos tokens JWT. Criaremos um novo arquivo para gerenciar a seguran√ßa: security.py. Nesse arquivo iniciaremos a gera√ß√£o dos tokens:

~~~shell
echo > .\mada\security.py
~~~

## Testando a gera√ß√£o de tokens
~~~shell
echo > .\tests\test_security.py
~~~

## Modificando o endpoint de POST para encriptar a senha

## Criando um endpoint de gera√ß√£o do token
### Utilizando OAuth2PasswordRequestForm
~~~shell
poetry add python-multipart
~~~

# Refatorando a Estrutura do Projeto

## Criando Routers
Criaremos inicialmente uma nova estrutura de diret√≥rios chamada routers dentro do seu projeto mada. Aqui, teremos subaplicativos dedicados a fun√ß√µes espec√≠ficas, como gerenciamento de usu√°rios e autentica√ß√£o.

‚îú‚îÄ‚îÄ mada  
‚îÇ  ‚îú‚îÄ‚îÄ app.py  
‚îÇ  ‚îú‚îÄ‚îÄ database.py  
‚îÇ  ‚îú‚îÄ‚îÄ models.py  
‚îÇ  ‚îú‚îÄ‚îÄ routers  
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ auth.py  
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ users.py  


#### Altera√ß√£o no teste do token
Arquivo `tests/test_app.py`

## Reestruturando os arquivos de testes
#### Executando os testes
~~~shell
task test
~~~

# Tornando o sistema de autentica√ß√£o robusto

## Testes para autentica√ß√£o

### Testando a altera√ß√£o de um usu√°rio n√£o autorizado

#### Criando modelos por demanda com factory-boy
O factory-boy √© uma biblioteca que nos permite criar objetos de modelo de teste de forma r√°pida e f√°cil. Com ele, podemos criar uma "f√°brica" de usu√°rios que produzir√° novos objetos de usu√°rio sempre que precisarmos. Isso nos permite criar m√∫ltiplos usu√°rios de teste com facilidade, o que √© perfeito para nosso cen√°rio atual.

~~~shell
poetry add --group dev factory-boy
~~~

Executando os testes abaixo em diante, o meu deu erro em alguns, logo, os testes seguintes n√£o foi poss√≠vel avaliar, verificar* (No final copiei tudo e vi que um arquivo precisava estar diferente, por√©m preciso rever sobre o token, pois isso est√° quebrando meus testes)

### Testes gerais
## Implementando o refresh do token

~~~shell
poetry add --group dev freezegun
~~~

## Estrutura inicial do c√≥digo
Primeiro, criaremos um novo arquivo chamado todos.py no diret√≥rio de routers:
~~~shell
echo > mada\routers\livros.py
~~~

## Implementa√ß√£o da tabela no Banco de dados

## Criando a migra√ß√£o da nova tabela
~~~shell
alembic revision --autogenerate -m "create livro table"
~~~

Depois que a migra√ß√£o for criada, precisamos aplic√°-la ao nosso banco de dados. Execute o comando alembic upgrade head para aplicar a migra√ß√£o.

~~~shell
alembic upgrade head
~~~

Agora que a migra√ß√£o foi aplicada, nosso banco de dados deve ter uma nova tabela de tarefas. Para verificar, voc√™ pode abrir o banco de dados com o comando sqlite3 database.db e depois executar o comando .schema para ver o esquema do banco de dados.

~~~shell
sqlite3 database.db
# ...
sqlite> .schema
# ...
~~~

### Endpoint de listagem

# Dockerizando a nossa aplica√ß√£o e introduzindo o PostgreSQL
### pr√©-requisitos
Para este caso espec√≠fico, tenho o Docker Desktop instalado no windows com o servi√ßo sempre parado, logo, precisa iniciar o servi√ßo do docker.

## Criando nosso Dockerfile

### Introduzindo o postgreSQL
#### Usar a Sintaxe Correta para cada SO Continua√ß√£o de Linhas no PowerShell
~~~shell
# Sintaxe para windows
docker run `
    --name app_database_v2 `
    -e POSTGRES_USER=app_user `
    -e POSTGRES_DB=app_db `
    -e POSTGRES_PASSWORD=app_password `
    -p 5432:5432 `
    postgres
~~~

Com o banco de dados criado, que pode ser verificado no Docker Desktop, vamos testar acesso com uma ferramenta de BD, neste caso √© o DBeaver.

Verificando o banco de dados docker via linha de comando:
~~~shell
docker ps -a -q # verifica os containers existentes inclusive os desligados
docker container start 6c13bcfa5e5f # iniciar o container
docker ps # verifica os containers iniciados
~~~

### Adicionando o suporte ao PostgreSQL na nossa aplica√ß√£o
~~~shell
poetry add "psycopg[binary]"
~~~

Para ajustar a conex√£o com o PostgreSQL, modifique seu arquivo `.env` para incluir a seguinte string de conex√£o:
~~~shell
DATABASE_URL="postgresql+psycopg://app_user:app_password@localhost:5432/app_db"
~~~

Atualizar o banco de dados com suas respectivas tabelas com o comando abaixo.
~~~shell
alembic upgrade head
~~~

Abrir o Dbeaver para ver o banco de dados e as tabelas

Agora testar ver se a aplica√ß√£o est√° rodando.
~~~shell
task run
~~~

## Resolvendo os testes que estavam rodando no sqlite
### Ajustando o arquivo `conftest.py`
Agora todos os meus testes passaram, mas dependem do banco de dados em p√©.

### Testando com Docker
Existe uma biblioteca python que gerencia as depend√™ncias de containers externos
para que a aplica√ß√£o seja executada. O TestContainers
~~~shell
poetry add --group dev testcontainers
~~~

## Parte 2 - Criando a imagem do nosso projeto
Criando na raiz o arquivo `Dockerfile`
~~~shell
echo > Dockerfile
~~~

Aqui est√° um exemplo de Dockerfile para criar o ambiente e executar nossa aplica√ß√£o:
~~~docker
FROM python:3.12-slim
ENV POETRY_VIRTUALENVS_CREATE=false

WORKDIR app/
COPY . .

RUN pip install poetry

RUN poetry config installer.max-workers 10
RUN poetry install --no-interaction --no-ansi

EXPOSE 8000
CMD poetry run uvicorn --host 0.0.0.0 mada.app:app
~~~

## Criando a imagem
Para criar uma imagem Docker a partir do Dockerfile, usamos o comando docker build. O comando a seguir cria uma imagem chamada "mada":
~~~shell
docker build -t "mada" .
~~~

Ent√£o verificaremos se a imagem foi criada com sucesso usando o comando:
~~~shell
docker images
~~~

## Executando o container
~~~shell
docker run -it --name mada -p 8000:8000 mada:latest
~~~

~~~shell
curl http://localhost:8000
~~~

## Parte 3 - Simplificando nosso fluxo com docker-compose
Cria√ß√£o do compose.yaml
~~~shell
echo > compose.yaml
~~~

~~~yaml
services:
  fastzero_database:
    image: postgres
    volumes:
      - pgdata:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: app_user
      POSTGRES_DB: app_db
      POSTGRES_PASSWORD: app_password
    ports:
      - "5432:5432"

  fastzero_app:
    image: mada_app
    entrypoint: ./entrypoint.sh
    build: .
    ports:
      - "8000:8000"
    depends_on:
      - mada_database
    environment:
      DATABASE_URL: postgresql+psycopg://app_user:app_password@mada_database:5432/app_db

volumes:
  pgdata:
~~~

~~~shell
docker-compose up
~~~

Caso d√™ algum erro de porta, derrube as imagens e crie o compose novamente.

## Implementando o Entrypoint
Criamos um script chamado entrypoint.sh que ir√° preparar nosso ambiente antes de a aplica√ß√£o iniciar:
~~~shell
echo > entrypoint.sh
~~~

~~~shell
#!/bin/sh

# Executa as migra√ß√µes do banco de dados
poetry run alembic upgrade head

# Inicia a aplica√ß√£o
poetry run uvicorn --host 0.0.0.0 --port 8000 mada.app:app
~~~

## Adicionando o Entrypoint ao Docker Compose:

Inclu√≠mos o entrypoint no nosso servi√ßo no arquivo compose.yaml, garantindo que esteja apontando para o script correto:

~~~shell
docker-compose up --build
~~~

Caso d√™ algum erro de execu√ß√£o no arquivo entrypoint, precisa dar poder de execu√ß√£o no mesmo.

~~~shell
docker-compose up -d mada_database
~~~

~~~shell
poetry add --group dev testcontainers
~~~


# Automatizando os testes com Integra√ß√£o Cont√≠nua (CI)
Criando os diret√≥rios
~~~shell
mkdir .github
~~~

~~~shell
mkdir .github/workflows
~~~

~~~shell
echo > .github/workflows/pipeline.yaml
~~~

Configurando o workflow de CI
As configura√ß√µes dos workflows no GitHub Actions s√£o definidas em um arquivo YAML localizado em um path especificado pelo github no reposit√≥rio .github/workflows/. Dentro desse diret√≥rio podemos criar quantos workflows quisermos. Iniciaremos nossa configura√ß√£o com um √∫nico arquivo que chamaremos de pipeline.yaml:

Atualizando as dependencias de arquivos do projeto `.github/workflows/pipeline.yaml`

Atualizando o reposit√≥rio e ver se executou os testes
~~~shell
git add .
git commit -m "Executando os testes no CI" 
git push 
~~~

## Configura√ß√£o de vari√°veis de ambiente no Actions
Com erro nos testes precisa configurar as vari√°veis de ambiente usando o gh. No c√≥digo abaixo ele vai criar segredo para todas as vari√°veis do arquivo.

~~~shell
gh secret set -f .env
~~~

Verificando os segredos
~~~shell
cat .env
~~~

Agora ir no reposit√≥rio https://github.com/LuizPerciliano/madaxxx e atualizar "Re-run jobs" apertando o bot√£o na aplica√ß√£o.

Deu erro pois faltou atualizar os segredos no `.github/workflows/pipeline.yaml`

# Fazendo deploy no Fly.io
## O Fly.io
O Fly.io √© uma plataforma de deploy que nos permite lan√ßar nossas aplica√ß√µes na nuvem e que oferece servi√ßos para diversas linguagens de programa√ß√£o e frameworks como Python e Django, PHP e Laravel, Ruby e Rails, Elixir e Phoenix, etc.

~~~shell
flyctl version
~~~

Agora precisa auntenticar no flyctl


## Configura√ß√µes para o deploy
Agora com o flyctl devidamente configurado. Podemos iniciar o processo de lan√ßamento da nossa aplica√ß√£o. O flyctl tem um comando espec√≠fico para lan√ßamento, o launch. Contudo, o comando launch √© bastante interativo e ao final dele, o deploy da aplica√ß√£o √© executado. Colocar a mem√≥ria de 512 para cima.
Para evitar o deploy no primeiro momento, pois ainda existem coisas para serem configuradas, vamos execut√°-lo da seguinte forma:

~~~shell
flyctl launch --no-deploy
~~~

Acessos:
- Admin URL: https://fly.io/apps/fastxxx


## Configura√ß√£o dos segredos
Para que nossa aplica√ß√£o funcione de maneira adequada, todas as vari√°veis de ambiente precisam estar configuradas no ambiente. O flyctl tem um comando para vermos as vari√°veis que j√° foram definidas no ambiente e tamb√©m para definir novas. O comando secrets.

Para vermos as vari√°veis j√° configuradas no ambiente, podemos executar o seguinte comando:
~~~shell
flyctl secrets list
~~~

Uma coisa que podemos notar na resposta do secrets √© que ele leu nosso arquivo .env e adicionou a vari√°vel de ambiente DATABASE_URL com base no postgres que foi criado durante o comando launch. Um ponto de aten√ß√£o que devemos tomar nesse momento, √© que a vari√°vel criada √© iniciada com o prefixo postgres://. Para que o sqlalchemy reconhe√ßa esse endere√ßo como v√°lido, o prefixo deve ser alterado para postgresql+psycopg://. Para isso, usaremos a url fornecida pelo comando launch e alterar o prefixo.

Desta forma, podemos registar a vari√°vel de ambiente DATABASE_URL novamente. Agora com o valor correto:

~~~shell
flyctl secrets set ALGORITHM="HS256"
~~~

~~~shell
flyctl secrets set ACCESS_TOKEN_EXPIRE_MINUTES=300
~~~

Para secret_key, tem que ter uma ou gerar. Como gerar uma?

~~~shell
python
import secrets
secrets.token_hex(32)
~~~

Com o comando acima ser√° gerado um segredo, basta copiar no comando abaixo e voil√°.

~~~shell
flyctl secrets set SECRET_KEY="your-secret-key"
~~~


Podemos registar a vari√°vel de ambiente DATABASE_URL novamente, agora a correta fornecida pelo fly.io. Agora com o valor correto:


~~~shell
flyctl secrets set DATABASE_URL="postgresql+psycopg://postgres:nome-user-do-app:senhageradanofly@nome-da-maquina-db.flycast:5432/nome-app‚Äù
~~~

## Deploy da aplica√ß√£o
Para efetuarmos o deploy da aplica√ß√£o, podemos usar o comando deploy doflyctl. Uma coisa interessante nessa parte do processo √© que o Fly pode fazer o deploy de duas formas:

Copiar seus arquivos e fazer o build do docker na nuvem;
Voc√™ pode fazer o build localmente e subir apenas o container para um reposit√≥rio dispon√≠vel no Fly.
Optaremos por fazer o build localmente para n√£o serem alocadas duas m√°quinas em nossa aplica√ß√£o1. Para executar o build localmente usamos a flag --local-only.

O Fly sobre duas inst√¢ncias por padr√£o da nossa aplica√ß√£o para melhorar a disponibilidade do app. Como vamos nos basear no uso gratuito, para todos poderem executar o deploy, adicionaremos a flag --ha=false ao deploy. Para desativamos a alta escalabilidade:

~~~shell
fly deploy --local-only --ha=false
~~~

Verificando o log da aplica√ß√£o.
~~~shell
fly logs -a mada
ou 
fly logs -a mada | tl # tem que ter a biblioteca tl instalada
ou site app
~~~

## Migrations
Agora que nosso container j√° est√° em execu√ß√£o no fly, podemos executar o comando de migra√ß√£o dos dados, pois ele est√° na mesma rede do postgres configurado pelo Fly2. Essa conex√£o √© feita via SSH e pode ser efetuada com o comando ssh do flyctl.

Podemos fazer isso de duas formas, acessando efetivamente o container remotamente ou enviando somente um comando para o Fly. Optarei pela segunda op√ß√£o, pois ela n√£o √© interativa e usar√° somente uma √∫nica chamada do shell. Desta forma:

Entrando na m√°quina no fly.io
~~~shell
flyctl ssh console
~~~

Colocar no dockeringone:
tests
imagens

Dentro do console √© poss√≠vel rodar a migra√ß√£o (alembic), pois as tabelas n√£o foram criadas.

~~~shell
alembic upgrade head
~~~

ou rodar diretamente o comando abaixo:

~~~shell
flyctl ssh console -a mada -C "poetry run alembic upgrade head"
~~~

## Atualizando o reposit√≥rio - Commit
Caso seja um reposit√≥rio de desenvolvimento compartilhado, verificar se no reposit√≥rio remoto h√° algo novo e pedir para baixar.
~~~shell
git pull
~~~

Verificar o status do reposit√≥rio para ver as mudan√ßas realizadas:
~~~shell
git status
~~~

Se tudo estiver ok, adicionar os arquivos, comitar e por fim enviar para o reposit√≥rio remoto.
~~~shell
git add . 
git commit -m "Adicionando arquivos gerados pelo Fly"
git push --set-upstream origin main 
~~~

Conferindo se subiu tudo ok
~~~shell
git log